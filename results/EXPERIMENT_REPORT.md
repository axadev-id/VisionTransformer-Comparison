# üî¨ Vision Transformer Comparison Experiment

## üìã Executive Summary

**Date**: 2025-11-21 22:24:50

**Dataset**: Custom Indonesian Food Dataset
**Classes**: 5 (bakso, gado_gado, nasi_goreng, rendang, soto_ayam)
**Total Images**: 1108
**Train/Val/Test Split**: 886/110/112

**Models Evaluated**: 3 (ViT, DeiT, MAE)
**Training Configuration**:
- Batch Size: 32
- Epochs: 10
- Learning Rate: 0.0003
- Image Size: 224x224
- Mixed Precision: Enabled

---

## üìä Results Summary

| Model | Accuracy | Precision | Recall | F1 Score | Parameters | Inference Time |
|-------|----------|-----------|--------|----------|------------|----------------|
| **VIT** | 84.82% | 0.8682 | 0.8509 | 0.8405 | 85.8M | 65.13 ms |
| **DEIT** | 94.64% | 0.9513 | 0.9453 | 0.9461 | 85.8M | 62.44 ms |
| **MAE** | 88.39% | 0.8926 | 0.8877 | 0.8838 | 85.8M | 244.27 ms |

---

## üèÜ Best Performers

- **üéØ Highest Accuracy**: DEIT (94.64%)
- **üìà Highest F1 Score**: DEIT (0.9461)
- **‚ö° Fastest Inference**: DEIT (62.44 ms)
- **üíæ Smallest Model**: VIT (85.8M parameters)

---

## üìà Model-Specific Analysis

### VIT

**Performance Metrics**:
- Test Accuracy: 84.82%
- Precision (Macro): 0.8682
- Recall (Macro): 0.8509
- F1 Score (Macro): 0.8405

**Model Characteristics**:
- Parameters: 85,802,501 (85.8M)
- Inference Time: 65.13 ms/image

**Training Progression**:
- Initial Train Loss: 1.9547
- Final Train Loss: 0.6009
- Best Validation Accuracy: 85.45% (Epoch 10)

### DEIT

**Performance Metrics**:
- Test Accuracy: 94.64%
- Precision (Macro): 0.9513
- Recall (Macro): 0.9453
- F1 Score (Macro): 0.9461

**Model Characteristics**:
- Parameters: 85,807,882 (85.8M)
- Inference Time: 62.44 ms/image

**Training Progression**:
- Initial Train Loss: 0.5096
- Final Train Loss: 0.0100
- Best Validation Accuracy: 95.45% (Epoch 4)

### MAE

**Performance Metrics**:
- Test Accuracy: 88.39%
- Precision (Macro): 0.8926
- Recall (Macro): 0.8877
- F1 Score (Macro): 0.8838

**Model Characteristics**:
- Parameters: 85,802,501 (85.8M)
- Inference Time: 244.27 ms/image

**Training Progression**:
- Initial Train Loss: 2.1933
- Final Train Loss: 0.3486
- Best Validation Accuracy: 90.91% (Epoch 9)

---

## üí° Key Insights & Recommendations

1. **Average Performance**: All models achieved 89.29% mean accuracy
2. **Model Consistency**: Low variance (0.0406 std dev) between models
3. **Best Choice for Accuracy**: DEIT model recommended for maximum performance
4. **Best Choice for Speed**: DEIT model recommended for real-time applications
5. **Best Choice for Deployment**: VIT model recommended for resource-constrained environments

---

## üìÇ Generated Artifacts

- Model checkpoints: `checkpoints/`
- Confusion matrices: `results/confusion_matrices/`
- Learning curves: `results/learning_curves/`
- Comparison charts: `results/model_comparison.png`
- Summary table: `results/summary_comparison.csv`

---

## üéì Conclusion

This experiment successfully compared three Vision Transformer architectures (ViT, DeiT, MAE) on Indonesian Food classification dataset with 5 classes. DEIT achieved the best accuracy (94.64%), while DEIT provided the fastest inference (62.44 ms). All models demonstrated strong performance, validating the effectiveness of Vision Transformers for this image classification task.

**Bonus Eligibility**: ‚úÖ **3 models compared** (ViT, DeiT, MAE) ‚Üí **140/100** possible

---

*Report generated automatically by Vision Transformer Experiment Pipeline*
